{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "298ab3c0-fbb3-42aa-8455-5fb4fa912c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math as mt\n",
    "from metpy.interpolate import interpolate_to_points\n",
    "import scipy.optimize as spo\n",
    "import time \n",
    "from joblib import Parallel, delayed\n",
    "import glob\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253eea39-3548-45eb-928c-8751a1375381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f2e924-52a7-46b0-9cb8-8844a2f92ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the pulse field\n",
    "\n",
    "def gen_field(dur_max, dur_step):\n",
    "    pdur_i0 = ppau_i0 = np.arange(0, dur_max, dur_step)\n",
    "    pdur_j, ppau_j = np.meshgrid(pdur_i0, ppau_i0)\n",
    "    return pdur_j, ppau_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64ab6b7-dee9-4bdb-9056-cd7a2ecd6fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the data\n",
    "\n",
    "def plot_field(pdur, ppau, res):\n",
    "    plt.pcolor(pdur, ppau, res, cmap='Reds')\n",
    "    plt.xlim(0, np.max(pdur))\n",
    "    plt.ylim(0, np.max(ppau))\n",
    "    plt.colorbar(label='Phonotaxis')\n",
    "    plt.xlabel('Pulse [ms]')\n",
    "    plt.ylabel('Pause [ms]')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c29852-5853-4caf-8986-42ac2c5a5770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering data to have similar chirp structure and eliminating redundancies in pulse pause and duration\n",
    "\n",
    "def filter_data(x, dur_max):\n",
    "    pd_df = x\n",
    "    \n",
    "    #finding frequency of each chirp duration\n",
    "    x = np.array(pd_df.CDUR)\n",
    "    x = x.astype(int)\n",
    "    (uniq, freq) = (np.unique(x, return_counts=True))\n",
    "    xa = np.array([uniq,freq])\n",
    "\n",
    "    #finding the bracket of 61 values with the most data points\n",
    "    if (np.max(xa[0]) - np.min(xa[0])) > 60: #Checking if the range of available points exceeds interested bracket size\n",
    "        jo = np.zeros(np.max(xa[0]))\n",
    "        jo[xa[0]-1] = freq\n",
    "        jo2 = []\n",
    "        for i in range(30,len(jo)-30):\n",
    "            jo2.append([i, np.sum(jo[i-30:i+30])])\n",
    "        jo2 = np.array(jo2).T\n",
    "        j = np.where(jo2 == np.max(jo2[1]))\n",
    "        val = j[1][1] + 31\n",
    "\n",
    "        #filtering down to values in the bracket calculated above\n",
    "        x = pd_df.CDUR\n",
    "        x1 = x>=(val-30)\n",
    "        xa = pd_df[x1]\n",
    "        x2 = xa.CDUR<=(val+30)\n",
    "        xb = xa[x2]\n",
    "    \n",
    "    else: \n",
    "        xb = pd_df\n",
    "    \n",
    "    #repeating the same procedure for the values in chirp pause\n",
    "    pd_df = xb\n",
    "    x = np.array(pd_df.CPAU)\n",
    "    x = x.astype(int)\n",
    "    (uniq, freq) = (np.unique(x, return_counts=True))\n",
    "    xa = np.array([uniq,freq])\n",
    "\n",
    "    if (np.max(xa[0]) - np.min(xa[0])) > 60:\n",
    "        jo = np.zeros(np.max(xa[0]))\n",
    "        jo[xa[0]-1] = freq\n",
    "        jo2 = []\n",
    "        for i in range(30,len(jo)-30):\n",
    "            jo2.append([i, np.sum(jo[i-30:i+30])])\n",
    "        jo2 = np.array(jo2).T\n",
    "        j = np.where(jo2 == np.max(jo2[1]))\n",
    "        val = j[1][1] + 31\n",
    "\n",
    "        x = pd_df.CPAU\n",
    "        x1 = x>=(val-30)\n",
    "        xa = pd_df[x1]\n",
    "        x2 = xa.CPAU<=(val+30)\n",
    "        xb1 = xa[x2]\n",
    "    \n",
    "    else: \n",
    "        xb1 = xb\n",
    "\n",
    "    #averaging the duplicates\n",
    "    dfa = pd.DataFrame([xb1.PDUR, xb1.PPAU, xb1.rXY]).T\n",
    "    dfx = dfa.groupby(['PPAU', 'PDUR']).mean().reset_index()\n",
    "    \n",
    "    #filtering for values under the maximum duration specified\n",
    "    check = dfx<=dur_max\n",
    "    df_c = np.all(check,1)\n",
    "    dfx = dfx[df_c]\n",
    "    \n",
    "    dfx = np.array([dfx.PDUR, dfx.PPAU, dfx.rXY]).T\n",
    "    \n",
    "    dur_max = np.max([np.max(dfx.T[0]), np.max(dfx.T[1])])\n",
    "    print(dur_max)\n",
    "    dur_max = int(dur_max*1.25)\n",
    "    dur_steps = int(np.sqrt((dur_max**2 * 16)/2500))/4\n",
    "    print(dur_steps)\n",
    "    \n",
    "    edg = [[0,0,0], [0, dur_max, 0], [dur_max, dur_max, 0], [dur_max,0,0]] #initializing origin to zero (for smooth interpolation purposes)\n",
    "    dfx = np.append(dfx, edg, axis = 0) \n",
    "    dfx = dfx.T\n",
    "    \n",
    "    #plotting for verifying of data points\n",
    "    plt.plot(dfx[0], dfx[1], 'o')\n",
    "    plt.xlim(0, dur_max)\n",
    "    plt.ylim(0, dur_max)\n",
    "    plt.show()\n",
    "    return dfx, dur_max, dur_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b6033fe-8c0b-44c9-9e0a-2fb2d43a3c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data from file\n",
    "\n",
    "def import_data(species, dur_max):\n",
    "    \n",
    "    pd_df = species\n",
    "    df, dur_max, dur_step = filter_data(pd_df, dur_max)    \n",
    "    \n",
    "    pdur = df[0]\n",
    "    ppau = df[1]\n",
    "    phonotaxis = df[2]\n",
    "\n",
    "    np.random.seed(10)\n",
    "    # need to jitter data points slightly for interp to work - probably a bug in metpy\n",
    "    points = np.array([pdur + np.random.randn(*pdur.shape)/10000000, ppau + np.random.randn(*ppau.shape)/10000000]).T\n",
    "\n",
    "    # make new grid of points to interpolate to\n",
    "    pdur_i0 = ppau_i0 = np.arange(0, dur_max, dur_step)\n",
    "    pdur_i, ppau_i = np.meshgrid(pdur_i0, ppau_i0)\n",
    "    new_points = np.array([pdur_i, ppau_i]).T.reshape((-1, 2))\n",
    "\n",
    "    # natural neighbour interpolation \n",
    "    ppf = interpolate_to_points(points, phonotaxis, new_points, interp_type='natural_neighbor')\n",
    "    ppf[np.isnan(ppf)] = 0 #np.nanmean(ppf)\n",
    "    ppf = np.maximum(ppf, 0)  # set neg vals to 0\n",
    "    ppf = ppf.reshape((len(pdur_i), len(ppau_i))).T  # make interpolated ppf square\n",
    "    \n",
    "    ppf /= np.max(ppf)\n",
    "    return ppf, dur_max, dur_step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fa7117d-06ea-4739-abdc-85846f690904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating the signal from the parameter duty cycle\n",
    "\n",
    "def signal(idur, ipau, sf):\n",
    "    sf = int(sf)\n",
    "    unit = (sf/1000)\n",
    "    dur = int(unit*idur)\n",
    "    pau = int(unit*ipau)\n",
    "    #print(dur, pau, unit)\n",
    "    adur = np.ones(dur, dtype = int)\n",
    "    apau = np.zeros(pau, dtype = int)\n",
    "    aper = np.concatenate((adur,apau))\n",
    "    sig2 = np.tile(aper, sf)\n",
    "    if len(sig2)>sf:\n",
    "        sig = sig2[0:sf]\n",
    "    else:\n",
    "        l = sf - len(sig2)\n",
    "        sig3 = np.zeros(l, dtype = int)\n",
    "        sig = np.concatenate((sig2, sig3))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02328924-01c0-4729-b0e0-4e3bae364094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Gabor filter\n",
    "\n",
    "def gabor(fr, sigma, phi, w, sf):\n",
    "    border = int((3.5*sigma)) \n",
    "    t =  np.arange(-border, border, 1000/sf) #in ms\n",
    "    gaussian = np.exp(-(t)**2/(2*sigma**2)) # in ms\n",
    "    sinusoidal = np.sin(2*np.pi*(fr/1000)*t + phi) # in KHz, ms\n",
    "    gbr =  gaussian * sinusoidal + w\n",
    "    return gbr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44bb00c4-7c5d-4517-bd81-9717903081ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear nonlinear filtering (including the integration)\n",
    "\n",
    "def lin_nonlin(sig, gab, a1, b1):\n",
    "    f1 = np.convolve(sig, gab) #linear filter\n",
    "    \n",
    "    g1 = 1/(1 + np.exp( -(a1 * f1) + b1)) # nonlinear sigmoid function\n",
    "\n",
    "    #integral (which is basically summation)\n",
    "    v1 = 0.001 * g1.sum()\n",
    "    return v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faee15b9-1350-48cd-8504-544cc635af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting Phonotaxis value by pushing fabricated signal through filter\n",
    "\n",
    "def phonotaxis(fr, sigma, phi, w, a1, b1, sf, t1, t2):\n",
    "    sig1 = signal(t1, t2, sf)\n",
    "    gab1 = gabor(fr, sigma, phi, w, sf)\n",
    "    phntxs = lin_nonlin(sig1, gab1, a1, b1)\n",
    "    return phntxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97fdbfdc-3f98-43df-b4a0-6cf96a8dd0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the entire model as a single function which is to be minimized \n",
    "#the function calculates the difference between the generated pulse-pause preference data and the actual experimental data imported earlier in the program.\n",
    "\n",
    "def sig_diff(cfg):\n",
    "    fr, sigma, ph, w, a1, b1 = cfg #unpacking the command from gods\n",
    "    phi = np.pi * ph\n",
    "\n",
    "    #generate field\n",
    "    sf = 2000\n",
    "    \n",
    "    #calculating phonotaxis values\n",
    "    phono = np.vectorize(phonotaxis)\n",
    "    pnt = phono(fr, sigma, phi, w, a1, b1, sf, pdur_i, ppau_i)\n",
    "    \n",
    "    #normalization\n",
    "    pnt = np.maximum(pnt, 0)\n",
    "    if (np.max(pnt) - np.min(pnt)) > 0:\n",
    "        pnt = (pnt - np.min(pnt))/(np.max(pnt) - np.min(pnt))\n",
    "    else:\n",
    "        pnt = (pnt - np.min(pnt))\n",
    "    #RMS of difference\n",
    "    diff = np.sqrt(np.mean((pnt - pnt_ori)**2))\n",
    "    \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbdb1864-138f-4164-8ac4-0ca1efffbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redundant function for crossverification and plotting\n",
    "\n",
    "def sig_diff2(cfg):\n",
    "    fr, sigma, ph, w, a1, b1 = cfg #unpacking the command from gods\n",
    "    phi = np.pi * ph\n",
    "\n",
    "    #generate field\n",
    "    sf = 2000\n",
    "    \n",
    "    #calculating phonotaxis values\n",
    "    phono = np.vectorize(phonotaxis)\n",
    "    pnt = phono(fr, sigma, phi, w, a1, b1, sf, pdur_i, ppau_i)\n",
    "    \n",
    "    #normalization\n",
    "    pnt = np.maximum(pnt, 0)\n",
    "    if (np.max(pnt) - np.min(pnt)) > 0:\n",
    "        pnt = (pnt - np.min(pnt))/(np.max(pnt) - np.min(pnt))\n",
    "    else:\n",
    "        pnt = (pnt - np.min(pnt))\n",
    "    #RMS of difference\n",
    "    diff = np.sqrt(np.mean((pnt - pnt_ori)**2))\n",
    "    \n",
    "    return diff, pnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8a12d50-723d-45a9-99f1-af1b6c30d26e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example parameters for signal generation\n",
    "# sf = 2000\n",
    "\n",
    "# #PARAMETERS OF GABOR FUNCTION\n",
    "# #frequency for the Gabor filter - INFLUENCES pulse period preference\n",
    "# fr = 50 #in Hz\n",
    "# #sharpness of tuning for pulse period\n",
    "# sigma = 50 \n",
    "# #phase shift - change the integer to change the phase \n",
    "# phi = np.pi * 0 \n",
    "# #offset - INFLUENCES duty cycle preference\n",
    "# w = 0\n",
    "\n",
    "# #parameters for Lin_nonlinear\n",
    "# a1 = 0.05 #slope/steepness of sigmoid\n",
    "# b1 = 1 #1/2 of max of non linearity\n",
    "\n",
    "# #pulse pause field sampling range and frequency(step)\n",
    "# dur_max = 20  # ms\n",
    "# dur_step = 0.5  # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "789942bd-073e-4a40-901c-0a6b757f9bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all files in folder\n",
    "\n",
    "def file_extract():\n",
    "    files = glob.glob('dat/Xls/*.csv')\n",
    "    data = []\n",
    "    for file in files:\n",
    "        data.append(pd.read_csv(file))\n",
    "    file_no = len(data)\n",
    "    # for i in range(file_no)\n",
    "    filename = files\n",
    "    filename = [s.replace('dat/Xls/', '').replace('_ppf.csv', '') for s in filename] \n",
    "    kou = [filename, data] #knowledge of universe\n",
    "    return kou \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "886599c5-f2b9-402f-88d3-f44b5aa15c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_fit(cfg, temp):\n",
    "\n",
    "    #setting predetermined initial parameters, evaluating the start point of minimize function and plotting the ppf corresponding to the initial parameters\\\n",
    "    print(cfg)\n",
    "    y = sig_diff(cfg)\n",
    "    print(y)\n",
    "    xz = sig_diff2(cfg)\n",
    "    plot_field(pdur_i, ppau_i, xz[1])\n",
    "\n",
    "    #bounds of each parameter\n",
    "\n",
    "    b_fr = (0, 700)\n",
    "    b_sigma = (1, 501)\n",
    "    b_phi = (0, 2)\n",
    "    b_w = (-1, 1)\n",
    "    b_a1 = (0, np.inf)\n",
    "    b_b1 = (-np.inf, np.inf)\n",
    "    bnds = (b_fr, b_sigma, b_phi, b_w, b_a1, b_b1)\n",
    "    \n",
    "    # Basin hopping minimization - to find the closest fit with the existing data without getting stuck in a local minima. 'options' : {\"disp\": True },\n",
    "\n",
    "    result = spo.basinhopping(sig_diff, cfg, niter = 100, T=temp, minimizer_kwargs={ 'bounds' : bnds,  'method' : 'L-BFGS-B'}) \n",
    "\n",
    "    if result.fun >= 0.12:\n",
    "        temp = temp+0.01\n",
    "        best_fit(cfg, temp)\n",
    "    \n",
    "    print(result)\n",
    "    xe = sig_diff2(result.x)\n",
    "    plot_field(pdur_i, ppau_i, xe[1])\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b98db7dc-1499-480c-9cd4-ee7533fea505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all files in folder\n",
    "\n",
    "def file_extract():\n",
    "    files = glob.glob('dat/Xls/*.csv')\n",
    "    data = []\n",
    "    for file in files:\n",
    "        data.append(pd.read_csv(file))\n",
    "    file_no = len(data)\n",
    "    # for i in range(file_no)\n",
    "    filename = files\n",
    "    filename = [s.replace('dat/Xls/', '').replace('_ppf.csv', '') for s in filename] \n",
    "    kou = [filename, data] #knowledge of universe\n",
    "    return filename, data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ded86f4-7e9f-483c-b3a2-31cb1e0f6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_call(i):\n",
    "    #predetermined list of initial parameters\n",
    "    cfg_list = [[13, 22, 1.4, -0.08, 0.23, 5], [130, 7, 1.4, 0.0, 0.15, 5],[60, 20, 1.4, 0.0, 0.15, 5],[28, 20, 1.4, -0.02, 0.19, 5],[18, 32, 0.5, -0.003, 0.09, 15], [16, 15, 0.5, -0.2, 0.13, 29], [30, 17, 0.5, 0.0, 0.04, 29],[90, 4, 1, 0.0, 0.001, 29],[70, 17, 1, 0.0, 0.1, 29], [65, 10, 0, 0.0, 0.01, 8], [12, 120, 1.1, 0.0, 0.0001, 3], [30, 35, 1.5, -0.002, 0.01, 30], [60, 2, 0, 0.0, 0.2, 30], [60, 2, 0, 0.0, 0.2, 30], [60, 15, 0, 0.0, 0.01, 10], [28, 15, 0.5, -0.02, 0.09, 52], [30, 20, 0.9, -0.02, 0.09, 52], [30, 20, 1.3, -0.04, 0.09, 10], [30, 19, 1.3, -0.04, 0.15, 10]]\n",
    "    cfg_name = ['ADO', 'ANU', 'ARM', 'BIM', 'FIR', 'G13', 'G14', 'G15', 'GSP', 'LIN', 'LOC', 'OVI', 'PER', 'RUB', 'TEX', 'TUL', 'VEL', 'VOX', 'YUC']\n",
    "    cfg_array = np.array(cfg_list)\n",
    "    \n",
    "    dataname, data = file_extract()\n",
    "    del data[11]\n",
    "    del dataname[11]\n",
    "    \n",
    "    temp = 0.01\n",
    "    \n",
    "    # all_results = []\n",
    "    \n",
    "    dur_max = 80  # ms\n",
    "    global pnt_ori, pdur_i, ppau_i\n",
    "    unpack = import_data(data[i], dur_max)\n",
    "    pnt_ori = unpack[0]\n",
    "    dur_max = unpack[1] #in ms\n",
    "    dur_step = unpack[2] #in ms\n",
    "    pnt_ori /= np.max(pnt_ori)\n",
    "    pdur_i, ppau_i = gen_field(dur_max, dur_step)\n",
    "\n",
    "    #Plot original datapoints for reference\n",
    "    plot_field(pdur_i, ppau_i, pnt_ori)\n",
    "\n",
    "    cfg = cfg_list[i]\n",
    "\n",
    "    print(cfg_name[i])\n",
    "\n",
    "    res = best_fit(cfg, temp)\n",
    "    xe = sig_diff2(res.x)\n",
    "    plot_field(pdur_i, ppau_i, xe[1])\n",
    "    # all_results.append(res)\n",
    "        \n",
    "    return res\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07b597ae-68ac-44d4-b709-cc51b2a8cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    all_res = Parallel(n_jobs=10)(delayed(func_call)(i) for i in range(19))\n",
    "    return all_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e80cb-7bfe-405c-b3d3-616c55a74cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10542/3250708937.py:40: RuntimeWarning: overflow encountered in long_scalars\n",
      "/tmp/ipykernel_10542/3250708937.py:40: RuntimeWarning: overflow encountered in long_scalars\n",
      "/tmp/ipykernel_10542/901067433.py:6: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_10542/901067433.py:6: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_10542/901067433.py:6: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_10542/901067433.py:6: RuntimeWarning: overflow encountered in exp\n",
      "/tmp/ipykernel_10542/901067433.py:6: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3901b-c5ab-44dd-9448-54551592b8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
